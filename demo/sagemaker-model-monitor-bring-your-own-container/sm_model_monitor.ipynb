{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sharp-minority",
   "metadata": {},
   "source": [
    "# Bring your own custom drift detector with Amazon SageMaker Model Monitor\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "* Host a machine learning model in Amazon SageMaker and capture inference requests, results, and metadata\n",
    "* Build a Docker container to include your custom drift algorithms\n",
    "* Monitor a live endpoint for detecting drifts\n",
    "* Visualize the drift results\n",
    "\n",
    "## Background\n",
    "\n",
    "Amazon SageMaker provides every developer and data scientist with the ability to build, train, and deploy machine learning models quickly. Amazon SageMaker is a fully-managed service that encompasses the entire machine learning workflow. You can label and prepare your data, choose an algorithm, train a model, and then tune and optimize it for deployment. You can deploy your models to production with Amazon SageMaker to make predictions and lower costs than was previously possible.\n",
    "\n",
    "In addition, Amazon SageMaker enables you to capture the input, output and metadata for invocations of the models that you deploy. It also enables you to bring your own metrics to analyze the data and monitor its quality. In this notebook, you learn how Amazon SageMaker enables these capabilities.\n",
    "\n",
    "## Setup\n",
    "\n",
    "To get started, make sure you have these prerequisites completed.\n",
    "\n",
    "* Specify an AWS Region to host your model.\n",
    "* An IAM role ARN exists that is used to give Amazon SageMaker access to your data in Amazon Simple Storage Service (Amazon S3). See the documentation for how to fine tune the permissions needed.\n",
    "* Create an S3 bucket used to store the data used to train your model, any additional model data, and the data captured from model invocations. For demonstration purposes, you are using the same bucket for these. In reality, you might want to separate them with different security policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minus-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "Demo Bucket: sagemaker-ap-southeast-1-342474125894\n",
      "Capture path: s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/datacapture\n",
      "Report path: s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/reports\n"
     ]
    }
   ],
   "source": [
    "# Handful of configuration\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from sagemaker import get_execution_role, session\n",
    "\n",
    "region= boto3.Session().region_name\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "# You can use a different bucket, but make sure the role you chose for this notebook\n",
    "# has the s3:PutObject permissions. This is the bucket into which the data is captured\n",
    "bucket =  session.Session(boto3.Session()).default_bucket()\n",
    "print(\"Demo Bucket: {}\".format(bucket))\n",
    "prefix = 'sagemaker/DEMO-ModelMonitor'\n",
    "\n",
    "s3_capture_upload_path = f's3://{bucket}/{prefix}/datacapture'\n",
    "s3_report_path = f's3://{bucket}/{prefix}/reports'\n",
    "\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-launch",
   "metadata": {},
   "source": [
    "### Upload train and test datasets, and model file to S3\n",
    "\n",
    "The dataset is taken from [UCI Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/adult). The task is to predict whether income exceeds $50K/yr based on census data. We have split the dataset into train and test datasets. The model was trained using XGBoost and the model file is provided here. \n",
    "\n",
    "We need test datasets for calculating projected accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extra-overhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! You are all set to proceed.\n"
     ]
    }
   ],
   "source": [
    "# Trained model\n",
    "model_file = open(\"model/model.tar.gz\", 'rb')\n",
    "\n",
    "# Training data for model development (with header and label column)\n",
    "train_file = open(\"data/train.csv\", 'rb')\n",
    "# Hold out test data\n",
    "test_file = open(\"data/test.csv\", 'rb')\n",
    "\n",
    "s3_model_key = os.path.join(prefix, 'model.tar.gz')\n",
    "s3_train_key = os.path.join(prefix, 'train.csv')\n",
    "s3_test_key = os.path.join(prefix, 'test.csv')\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_model_key).upload_fileobj(model_file)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_train_key).upload_fileobj(train_file)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_test_key).upload_fileobj(test_file)\n",
    "\n",
    "print(\"Success! You are all set to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-temperature",
   "metadata": {},
   "source": [
    "## Bring your own custom model drift detection algorithm\n",
    "\n",
    "In order to bring your own custom model drift detection algorithm, you need to do following things:\n",
    "* Create custom detection algorithms. We have included algorithms under src folder\n",
    "* Create a Docker container.\n",
    "* Set enviornmental variables where the container can find the datacapture data from SageMaker Model Monitor. These variables have to match with the values we provide to monitor scheduler later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mpython:3.8-slim-buster\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m pip3 install \u001b[31mpandas\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.1.4 \u001b[31mnumpy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.19.4 scikit-learn==\u001b[34m0\u001b[39;49;00m.23.2 \u001b[31mscipy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.5.4 \u001b[31mboto3\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.17.12\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /home\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mCOPY\u001b[39;49;00m src/* /home/\n",
      "\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"python3\"\u001b[39;49;00m, \u001b[33m\"drift_detector.py\"\u001b[39;49;00m]\n"
     ]
    }
   ],
   "source": [
    "!pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-matrix",
   "metadata": {},
   "source": [
    "### Build the container and upload it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "printable-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building docker image custom-model-monitor from Dockerfile\n",
      "$ docker build -t custom-model-monitor -f Dockerfile .\n",
      "Sending build context to Docker daemon  40.24MB\n",
      "Step 1/5 : FROM python:3.8-slim-buster\n",
      " ---> 6e66513aef39\n",
      "Step 2/5 : RUN pip3 install pandas==1.1.4 numpy==1.19.4 scikit-learn==0.23.2 scipy==1.5.4 boto3==1.17.12\n",
      " ---> Using cache\n",
      " ---> 663d56544432\n",
      "Step 3/5 : WORKDIR /home\n",
      " ---> Using cache\n",
      " ---> 12399f02e946\n",
      "Step 4/5 : COPY src/* /home/\n",
      " ---> 2c9724be939c\n",
      "Step 5/5 : ENTRYPOINT [\"python3\", \"drift_detector.py\"]\n",
      " ---> Running in 54a22c3e4b30\n",
      "Removing intermediate container 54a22c3e4b30\n",
      " ---> b745ec2262ca\n",
      "Successfully built b745ec2262ca\n",
      "Successfully tagged custom-model-monitor:latest\n",
      "Done building docker image custom-model-monitor\n",
      "ECR repository already exists: custom-model-monitor\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Logged into ECR\n",
      "$ docker tag custom-model-monitor 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/custom-model-monitor\n",
      "Pushing docker image to ECR repository 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/custom-model-monitor\n",
      "\n",
      "$ docker push 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/custom-model-monitor\n",
      "Using default tag: latest\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/custom-model-monitor]\n",
      "df90d9432b6d: Preparing\n",
      "294f0b92ae44: Preparing\n",
      "43dad4e4c8d6: Preparing\n",
      "3d87bad46e85: Preparing\n",
      "122f23a262d8: Preparing\n",
      "53264a515eac: Preparing\n",
      "814bff734324: Preparing\n",
      "53264a515eac: Waiting\n",
      "122f23a262d8: Layer already exists\n",
      "294f0b92ae44: Layer already exists\n",
      "43dad4e4c8d6: Layer already exists\n",
      "3d87bad46e85: Layer already exists\n",
      "53264a515eac: Layer already exists\n",
      "814bff734324: Layer already exists\n",
      "df90d9432b6d: Pushed\n",
      "latest: digest: sha256:c1f1d205a2b8f061fa24e3023a62bd0c884a94b9ccdf6e69e2a258fa565d7713 size: 1791\n",
      "Done pushing 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/custom-model-monitor\n"
     ]
    }
   ],
   "source": [
    "from docker_utils import build_and_push_docker_image\n",
    "\n",
    "repository_short_name = 'custom-model-monitor'\n",
    "\n",
    "image_name = build_and_push_docker_image(repository_short_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-resort",
   "metadata": {},
   "source": [
    "## Setup endoint and enable data capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-validity",
   "metadata": {},
   "source": [
    "The data that is sent for inference to the endpoint needs to pre-processed before the XGBoost model can do prediction. Below code shows custom input handler for inference endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "original-nickname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#  Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#  Licensed under the Apache License, Version 2.0 (the \"License\").\u001b[39;49;00m\n",
      "\u001b[37m#  You may not use this file except in compliance with the License.\u001b[39;49;00m\n",
      "\u001b[37m#  A copy of the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#      http://www.apache.org/licenses/LICENSE-2.0\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#  or in the \"license\" file accompanying this file. This file is distributed\u001b[39;49;00m\n",
      "\u001b[37m#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\u001b[39;49;00m\n",
      "\u001b[37m#  express or implied. See the License for the specific language governing\u001b[39;49;00m\n",
      "\u001b[37m#  permissions and limitations under the License.\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpathlib\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StringIO\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mencoder\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mxgb_encoders\u001b[39;49;00m\n",
      "\n",
      "\n",
      "script_path = pathlib.Path(\u001b[31m__file__\u001b[39;49;00m).parent.absolute()\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mscript_path\u001b[33m}\u001b[39;49;00m\u001b[33m/preprocess.pkl\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "    preprocess = pickle.load(f) \n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    The SageMaker XGBoost model server receives the request data body and the content type,\u001b[39;49;00m\n",
      "\u001b[33m    and invokes the `input_fn`.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Return a DMatrix (an object that can be passed to predict_fn).\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m\"\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:        \n",
      "        df = pd.read_csv(StringIO(request_body), header=\u001b[34mNone\u001b[39;49;00m)\n",
      "        X = preprocess.transform(df)\n",
      "        \n",
      "        X_csv = StringIO()\n",
      "        pd.DataFrame(X).to_csv(X_csv, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\n",
      "        req_transformed = X_csv.getvalue().replace(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "                \n",
      "        \u001b[34mreturn\u001b[39;49;00m xgb_encoders.csv_to_dmatrix(req_transformed)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mContent type \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m is not supported.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(content_type)\n",
      "        )\n",
      "        \n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Deserialize and return fitted model.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    model_file = \u001b[33m\"\u001b[39;49;00m\u001b[33mxgboost-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    booster = pickle.load(\u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, model_file), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        \n",
      "    \u001b[34mreturn\u001b[39;49;00m booster      \n"
     ]
    }
   ],
   "source": [
    "!pygmentize script/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-proof",
   "metadata": {},
   "source": [
    "### Setting up model endpoint can take few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tough-lightning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "model_url = f's3://{bucket}/{s3_model_key}'\n",
    "\n",
    "xgb_inference_model = XGBoostModel(\n",
    "    model_data=model_url,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    source_dir='script',\n",
    "    framework_version='1.2-1',\n",
    ")\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture=True,\n",
    "                        sampling_percentage=100,\n",
    "                        destination_s3_uri=s3_capture_upload_path)\n",
    "\n",
    "predictor = xgb_inference_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    serializer=CSVSerializer(),\n",
    "    data_capture_config=data_capture_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-shame",
   "metadata": {},
   "source": [
    "## Create monitoring schedule to detect drifts on hourly basis\n",
    "\n",
    "Default Model monitor can be setup to monitor the inference on an hourly basis against the baseline metrics and violations. In this example, we are setting custom model monitor. For this purpose, we are using Boto3 calls directly to setup model monitor with the container we built above. Note that we need to setup input and output paths on the container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_path = f's3://{bucket}/{s3_train_key}'\n",
    "s3_test_path = f's3://{bucket}/{s3_test_key}'\n",
    "s3_result_path = f's3://{bucket}/{prefix}/result/{predictor.endpoint_name}'\n",
    "\n",
    "# Create endpoint monitor using custom container\n",
    "# 0/15 * * * ? *\n",
    "sm_client.create_monitoring_schedule(\n",
    "    MonitoringScheduleName=predictor.endpoint_name,\n",
    "    MonitoringScheduleConfig={\n",
    "        'ScheduleConfig': {\n",
    "            'ScheduleExpression': 'cron(0 * ? * * *)'\n",
    "        },\n",
    "        'MonitoringJobDefinition': {\n",
    "            'MonitoringInputs': [\n",
    "                {\n",
    "                    'EndpointInput': {\n",
    "                        'EndpointName': predictor.endpoint_name,\n",
    "                        'LocalPath': '/opt/ml/processing/endpointdata'\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "            'MonitoringOutputConfig': {\n",
    "                'MonitoringOutputs': [\n",
    "                    {\n",
    "                        'S3Output': {\n",
    "                            'S3Uri': s3_result_path,\n",
    "                            'LocalPath': '/opt/ml/processing/resultdata',\n",
    "                            'S3UploadMode': 'EndOfJob'\n",
    "                        }\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "            'MonitoringResources': {\n",
    "                'ClusterConfig': {\n",
    "                    'InstanceCount': 1,\n",
    "                    'InstanceType': 'ml.c5.xlarge',\n",
    "                    'VolumeSizeInGB': 10\n",
    "                }\n",
    "            },\n",
    "            'MonitoringAppSpecification': {\n",
    "                'ImageUri': image_name,\n",
    "                'ContainerArguments': [\n",
    "                    '--train_s3_uri',\n",
    "                    s3_train_path,\n",
    "                    '--test_s3_uri',\n",
    "                    s3_test_path,\n",
    "                    '--target_label',\n",
    "                    'income'\n",
    "                ]\n",
    "            },\n",
    "            'StoppingCondition': {\n",
    "                'MaxRuntimeInSeconds': 600\n",
    "            },\n",
    "            'Environment': {\n",
    "                'string': 'string'\n",
    "            },\n",
    "            'RoleArn': role\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "separate-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_train_path s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/train.csv\n",
      "s3_test_path s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/test.csv\n",
      "s3_result_path s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/result/sagemaker-xgboost-2021-08-12-13-54-00-173\n"
     ]
    }
   ],
   "source": [
    "print(\"s3_train_path\", s3_train_path)\n",
    "print(\"s3_test_path\", s3_test_path)\n",
    "print(\"s3_result_path\", s3_result_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-championship",
   "metadata": {},
   "source": [
    "## Start sending pre-configured traffic to endpoint\n",
    "\n",
    "The cell below starts a thread to send some pre-configured traffic at a constant rate to the endpoint. The data points have been pre-conditioned to have drift, so that we can visualize it later. The traffic is sent for about 10 hours. If you like to stop the traffic, you need to stop the kernel to terminate this thread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "terminal-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending test traffic to the endpoint sagemaker-xgboost-2021-08-12-13-54-00-173. \n",
      "Please wait...\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from time import time, sleep\n",
    "\n",
    "def invoke_endpoint(ep_name, file_name, runtime_client):\n",
    "    pre_time = time()\n",
    "    with open(file_name) as f:\n",
    "        count = len(f.read().split('\\n')) - 2 # Remove EOF and header\n",
    "    \n",
    "    # Calculate time needed to sleep between inference calls if we need to have a constant rate of calls for 10 hours\n",
    "    ten_hours_in_sec = 10*60*60\n",
    "    sleep_time = ten_hours_in_sec/count\n",
    "    \n",
    "    with open(file_name, 'r') as f:\n",
    "        next(f) # Skip header\n",
    "        \n",
    "        for ind, row in enumerate(f):   \n",
    "            start_time = time()\n",
    "            payload = row.rstrip('\\n')\n",
    "            response = runtime_client(data=payload)\n",
    "            \n",
    "            # Print every 15 minutes (900 seconds). Rate of send * number of secs = number to sends\n",
    "            if (ind+1) % int(count/ten_hours_in_sec*900) == 0:\n",
    "                print(f'Finished sending {ind+1} records.')\n",
    "            \n",
    "            # Sleep to ensure constant rate. Time spent for inference is subtracted\n",
    "            sleep(max(sleep_time - (time() - start_time), 0))\n",
    "                \n",
    "    print(\"Done!\")\n",
    "    \n",
    "print(f\"Sending test traffic to the endpoint {predictor.endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "thread = Thread(target = invoke_endpoint, args=(predictor.endpoint, 'data/infer.csv', predictor.predict))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-dragon",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "* Monitor schedule - needs to deleted before deleting endpoint\n",
    "* Delete endpoint\n",
    "* Delete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "crude-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleSummaries': [{'MonitoringScheduleName': 'sagemaker-xgboost-2021-08-12-13-54-00-173',\n",
       "   'MonitoringScheduleArn': 'arn:aws:sagemaker:ap-southeast-1:342474125894:monitoring-schedule/sagemaker-xgboost-2021-08-12-13-54-00-173',\n",
       "   'CreationTime': datetime.datetime(2021, 8, 12, 14, 0, 31, 617000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2021, 8, 12, 14, 0, 37, 795000, tzinfo=tzlocal()),\n",
       "   'MonitoringScheduleStatus': 'Scheduled',\n",
       "   'EndpointName': 'sagemaker-xgboost-2021-08-12-13-54-00-173',\n",
       "   'MonitoringType': 'DataQuality'}],\n",
       " 'ResponseMetadata': {'RequestId': 'a1dea2c1-e99d-471d-997a-f8f5b3c9669d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a1dea2c1-e99d-471d-997a-f8f5b3c9669d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '435',\n",
       "   'date': 'Thu, 12 Aug 2021 15:05:58 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished sending 1000 records.\n",
      "Finished sending 1250 records.\n"
     ]
    }
   ],
   "source": [
    "sm_client.list_monitoring_schedules(EndpointName=predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_client.delete_monitoring_schedule(MonitoringScheduleName=predictor.endpoint)\n",
    "\n",
    "# predictor.delete_endpoint()\n",
    "# predictor.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
