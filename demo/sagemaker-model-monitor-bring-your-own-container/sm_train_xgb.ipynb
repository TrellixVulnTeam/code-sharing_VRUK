{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e1172c",
   "metadata": {},
   "source": [
    "# Train a binary classifier to classify income as below 50k or above 50k from census data\n",
    "\n",
    "## Dataset Information:\n",
    "\n",
    "The dataset is obtained from [Adult Data Set](https://archive.ics.uci.edu/ml/datasets/Adult). It consists of many multivariate features including demographics and income information. The task is to predict, if the income of a person is above or below $50k. \n",
    "\n",
    "### Setup\n",
    "\n",
    "To get started, make sure you have these prerequisites completed.\n",
    "\n",
    "* Specify an AWS Region to host your model.\n",
    "* An IAM role ARN exists that is used to give Amazon SageMaker access to your data in Amazon Simple Storage Service (Amazon S3). See the documentation for how to fine tune the permissions needed.\n",
    "* Create an S3 bucket used to store the data used to train your model, any additional model data, and the data captured from model invocations. For demonstration purposes, you are using the same bucket for these. In reality, you might want to separate them with different security policies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152973f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 21.0.1 from /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pip (python 3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f0275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-ap-southeast-1-342474125894\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea767a84",
   "metadata": {},
   "source": [
    "### Download data from UCI repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3edde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
    "mv adult.data ./data/adult.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a126e1a",
   "metadata": {},
   "source": [
    "## Pre-process\n",
    "\n",
    "Create a Scikit-learn pipeline to handle pre-processing. It consists of following steps:\n",
    "* Create train-test split\n",
    "* Use simple imputer to substitute most frequent for categorical and mean for numerical features.\n",
    "* Use one-hot encoding for handling categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30bfcddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv with column names\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "df = pd.read_csv('data/adult.csv', names = column_names)\n",
    "\n",
    "df.replace('?',np.NaN,inplace=True)\n",
    "cols = df.columns[df.dtypes == \"object\"]\n",
    "for i in cols:\n",
    "    df[i] = df[i].str.replace(\" \", \"\")\n",
    "\n",
    "        \n",
    "df_train_val, df_test, = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_train_val_no_target = df_train_val.drop('income', axis=1)\n",
    "df_train_val.to_csv('data/train.csv', index=False)\n",
    "df_test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a8e6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_ind = [i for i, x in enumerate(df_train_val_no_target.dtypes) if x != object]\n",
    "cat_ind = [i for i, x in enumerate(df_train_val_no_target.dtypes) if x == object]\n",
    "\n",
    "numeric_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_ind),\n",
    "    ('cat', categorical_transformer, cat_ind)\n",
    "])\n",
    "\n",
    "X = preprocessor.fit_transform(df_train_val_no_target)\n",
    "\n",
    "y = LabelEncoder().fit_transform(df_train_val.income)\n",
    "# Insert label into 1st column to meet XGBoost specification\n",
    "X = np.insert(X, 0, y, axis=1)\n",
    "\n",
    "# Save the ColumnTransformer to be used during inference\n",
    "with open('script/preprocess.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fa7bb",
   "metadata": {},
   "source": [
    "### Train-val split\n",
    "Split the training set again to create validation set and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f47bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "np.savetxt(\"data/train_transform.csv\", X_train, delimiter=\",\", fmt='%f')\n",
    "np.savetxt(\"data/val_transform.csv\", X_val, delimiter=\",\", fmt='%f')\n",
    "\n",
    "prefix = 'sagemaker/DEMO-ModelMonitor'\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv'))\\\n",
    ".upload_file('data/train_transform.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv'))\\\n",
    ".upload_file('data/val_transform.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938d33b",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "We train the model using SageMaker built-in XGBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc8a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c47a8",
   "metadata": {},
   "source": [
    "Delete these files first:\n",
    "- s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/test.csv\n",
    "- s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363d8efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-12 13:46:28 Starting - Starting the training job...\n",
      "2021-08-12 13:46:29 Starting - Launching requested ML instancesProfilerReport-1628775987: InProgress\n",
      "...\n",
      "2021-08-12 13:47:22 Starting - Preparing the instances for training............\n",
      "2021-08-12 13:49:23 Downloading - Downloading input data\n",
      "2021-08-12 13:49:23 Training - Downloading the training image.....\u001b[34m[2021-08-12 13:50:07.548 ip-10-0-187-23.ap-southeast-1.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 23443 rows and 108 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 5861 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.14755#011validation-error:0.14417\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.14802#011validation-error:0.14366\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.14947#011validation-error:0.14503\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.14674#011validation-error:0.14400\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.14354#011validation-error:0.14315\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.14307#011validation-error:0.14383\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.14281#011validation-error:0.14059\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.14183#011validation-error:0.14178\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.14055#011validation-error:0.14093\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.14068#011validation-error:0.14025\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.13983#011validation-error:0.13991\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.13966#011validation-error:0.13940\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.13872#011validation-error:0.14247\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.13906#011validation-error:0.13974\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.13795#011validation-error:0.14127\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.13765#011validation-error:0.14008\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.13723#011validation-error:0.14042\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.13710#011validation-error:0.13974\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.13710#011validation-error:0.13991\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.13659#011validation-error:0.13991\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.13531#011validation-error:0.14008\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.13514#011validation-error:0.13906\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.13326#011validation-error:0.13803\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.13309#011validation-error:0.13820\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.13181#011validation-error:0.13735\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.13138#011validation-error:0.13786\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.13108#011validation-error:0.13684\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.13062#011validation-error:0.13667\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.13049#011validation-error:0.13598\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.13006#011validation-error:0.13615\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.12882#011validation-error:0.13598\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.12784#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.12776#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.12724#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.12652#011validation-error:0.13513\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.12618#011validation-error:0.13496\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.12614#011validation-error:0.13564\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.12567#011validation-error:0.13479\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.12584#011validation-error:0.13462\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.12558#011validation-error:0.13462\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.12528#011validation-error:0.13462\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.12464#011validation-error:0.13428\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.12447#011validation-error:0.13428\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.12341#011validation-error:0.13411\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.12400#011validation-error:0.13377\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.12362#011validation-error:0.13325\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.12315#011validation-error:0.13308\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.12336#011validation-error:0.13291\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.12285#011validation-error:0.13445\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.12272#011validation-error:0.13377\u001b[0m\n",
      "\n",
      "2021-08-12 13:50:23 Uploading - Uploading generated training model\n",
      "2021-08-12 13:50:23 Completed - Training job completed\n",
      "Training seconds: 80\n",
      "Billable seconds: 80\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.2-1')\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role_arn, \n",
    "                                    hyperparameters=hyperparameters,                                    \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6d253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-southeast-1-342474125894/sagemaker/DEMO-ModelMonitor/output/sagemaker-xgboost-2021-08-12-13-46-27-819/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Save the model to be used during inference\n",
    "!aws s3 cp {xgb.model_data} model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02957899",
   "metadata": {},
   "source": [
    "# Test predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e692a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23443, 109)\n",
      "(2, 108)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "infer_data = X[:2, 1:]\n",
    "print(infer_data.shape)\n",
    "infer_data_df = pd.DataFrame(infer_data)\n",
    "infer_data_df.to_csv(\"test_endpoint.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2485604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[0.1071833148598671]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "import numpy as np\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "endpoint_name = \"sagemaker-xgboost-2021-08-12-13-54-00-173\"\n",
    "payload = \"29,Private,133060,Assoc-acdm,10,Married-civ-spouse,Prof-specialty,Own-child,Other,Male,0,0,55,United-States\"\n",
    "\n",
    "xgb_predictor = Predictor(endpoint_name,serializer=CSVSerializer())\n",
    "xgb_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2da77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
